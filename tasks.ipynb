{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2409548a-188a-4c03-ba91-d4426843fb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c949eca7-ccaa-465b-a6f9-5c5ca557849e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 374ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c949eca7-ccaa-465b-a6f9-5c5ca557849e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/5ms)\n",
      "24/12/07 23:51:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"smokeDetecton\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4\")\\\n",
    "    .config(\"fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ecfe10-e5f7-4ae7-9c68-86b64b77cee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+---+----------+\n",
      "|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]|PM1.0|PM2.5|NC0.5|NC1.0|NC2.5|CNT|Fire Alarm|\n",
      "+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+---+----------+\n",
      "|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735|  0.0|  0.0|  0.0|  0.0|  0.0|  0|         0|\n",
      "|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744|  0.0|  0.0|  0.0|  0.0|  0.0|  1|         0|\n",
      "|1654733333|        20.029|      55.96|        0|      400| 12374|      18764|      939.738|  0.0|  0.0|  0.0|  0.0|  0.0|  2|         0|\n",
      "|1654733334|        20.044|      55.28|        0|      400| 12390|      18849|      939.736|  0.0|  0.0|  0.0|  0.0|  0.0|  3|         0|\n",
      "|1654733335|        20.059|      54.69|        0|      400| 12403|      18921|      939.744|  0.0|  0.0|  0.0|  0.0|  0.0|  4|         0|\n",
      "+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+---+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- UTC: integer (nullable = true)\n",
      " |-- Temperature[C]: double (nullable = true)\n",
      " |-- Humidity[%]: double (nullable = true)\n",
      " |-- TVOC[ppb]: integer (nullable = true)\n",
      " |-- eCO2[ppm]: integer (nullable = true)\n",
      " |-- Raw H2: integer (nullable = true)\n",
      " |-- Raw Ethanol: integer (nullable = true)\n",
      " |-- Pressure[hPa]: double (nullable = true)\n",
      " |-- PM1.0: double (nullable = true)\n",
      " |-- PM2.5: double (nullable = true)\n",
      " |-- NC0.5: double (nullable = true)\n",
      " |-- NC1.0: double (nullable = true)\n",
      " |-- NC2.5: double (nullable = true)\n",
      " |-- CNT: integer (nullable = true)\n",
      " |-- Fire Alarm: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the downloaded file\n",
    "file_path = \"/home/ec2-user/smoke_detection_iot.csv\"\n",
    "\n",
    "# Load the dataset into PySpark\n",
    "raw_data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Drops the unnecessary first column\n",
    "cleaned_data = raw_data.drop(\"_c0\")\n",
    "\n",
    "# Show the cleaned data\n",
    "cleaned_data.show(5)\n",
    "cleaned_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9356ad48-960f-4f50-bdc7-8188d98c7ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3.9/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.local/lib/python3.9/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5357525-752f-48ff-a828-c2525034e13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Data (with Year and Month columns):\n",
      "          UTC  Temperature[C]  Humidity[%]  TVOC[ppb]  eCO2[ppm]  Raw H2  \\\n",
      "0  1654733331          20.000        57.36          0        400   12306   \n",
      "1  1654733332          20.015        56.67          0        400   12345   \n",
      "2  1654733333          20.029        55.96          0        400   12374   \n",
      "3  1654733334          20.044        55.28          0        400   12390   \n",
      "4  1654733335          20.059        54.69          0        400   12403   \n",
      "\n",
      "   Raw Ethanol  Pressure[hPa]  PM1.0  PM2.5  NC0.5  NC1.0  NC2.5  CNT  \\\n",
      "0        18520        939.735    0.0    0.0    0.0    0.0    0.0    0   \n",
      "1        18651        939.744    0.0    0.0    0.0    0.0    0.0    1   \n",
      "2        18764        939.738    0.0    0.0    0.0    0.0    0.0    2   \n",
      "3        18849        939.736    0.0    0.0    0.0    0.0    0.0    3   \n",
      "4        18921        939.744    0.0    0.0    0.0    0.0    0.0    4   \n",
      "\n",
      "   Fire Alarm            Timestamp  Year  Month  \n",
      "0           0  2022-06-09 00:08:51  2022      6  \n",
      "1           0  2022-06-09 00:08:52  2022      6  \n",
      "2           0  2022-06-09 00:08:53  2022      6  \n",
      "3           0  2022-06-09 00:08:54  2022      6  \n",
      "4           0  2022-06-09 00:08:55  2022      6  \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_unixtime, month, year\n",
    "import pandas as pd\n",
    "\n",
    "# Convert UTC to timestamp format\n",
    "data_with_datetime = cleaned_data.withColumn(\"Timestamp\", from_unixtime(\"UTC\"))\n",
    "\n",
    "# Extract Year and Month from the Timestamp column\n",
    "data_with_datetime = data_with_datetime.withColumn(\"Year\", year(\"Timestamp\")) \\\n",
    "                                         .withColumn(\"Month\", month(\"Timestamp\"))\n",
    "\n",
    "# Convert the PySpark DataFrame to a Pandas DataFrame for better presentation\n",
    "pandas_data = data_with_datetime.toPandas()\n",
    "\n",
    "# Display the data in a clear format using Pandas\n",
    "print(\"\\nTransformed Data (with Year and Month columns):\")\n",
    "print(pandas_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38fafe15-4800-4dfb-8fe4-f3ba0e65f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to remove spaces or special characters (if needed)\n",
    "data_with_datetime = data_with_datetime.withColumnRenamed(\"Raw H2\", \"Raw_H2\") \\\n",
    "                                       .withColumnRenamed(\"Raw Ethanol\", \"Raw_Ethanol\") \\\n",
    "                                       .withColumnRenamed(\"TVOC[ppb]\", \"TVOC_ppb\") \\\n",
    "                                       .withColumnRenamed(\"Pressure[hPa]\", \"Pressure_hPa\") \\\n",
    "                                       .withColumnRenamed(\"PM2.5\", \"PM2_5\") \\\n",
    "                                       .withColumnRenamed(\"Fire Alarm\", \"Fire_Alarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a979d9e-437b-4d95-bd2a-ffa098d837de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------------+----------+\n",
      "|Year|Month|Total_Raw_Ethanol|Total_TVOC|\n",
      "+----+-----+-----------------+----------+\n",
      "|2022|    6|       1237209173| 121631063|\n",
      "+----+-----+-----------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Compute Total Raw Ethanol and TVOC per Month\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "monthly_emissions = data_with_datetime.groupBy(\"Year\", \"Month\") \\\n",
    "                                      .agg(\n",
    "                                          F.sum(\"Raw_Ethanol\").alias(\"Total_Raw_Ethanol\"),\n",
    "                                          F.sum(\"TVOC_ppb\").alias(\"Total_TVOC\")\n",
    "                                      )\n",
    "monthly_emissions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a40bf4-6337-49c8-99d9-f03c1150042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------------+----------------+-----------------+\n",
      "|Year|Month| Avg_Temperature|    Avg_Humidity|     Avg_Pressure|\n",
      "+----+-----+----------------+----------------+-----------------+\n",
      "|2022|    6|15.9704235829474|48.5394994411625|938.6276494651149|\n",
      "+----+-----+----------------+----------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Compute Average Temperature, Humidity, and Pressure per Month\n",
    "monthly_environmental_trends = data_with_datetime.groupBy(\"Year\", \"Month\") \\\n",
    "                                                 .agg(\n",
    "                                                     F.avg(\"Temperature[C]\").alias(\"Avg_Temperature\"),\n",
    "                                                     F.avg(\"Humidity[%]\").alias(\"Avg_Humidity\"),\n",
    "                                                     F.avg(\"Pressure_hPa\").alias(\"Avg_Pressure\")\n",
    "                                                 )\n",
    "monthly_environmental_trends.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b1e907-63f0-4316-b781-2e2d68347aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----------+--------+---------+------+-----------+------------+------+------+-------+-------+-----+----+----------+-------------------+----+-----+\n",
      "|       UTC|Temperature[C]|Humidity[%]|TVOC_ppb|eCO2[ppm]|Raw_H2|Raw_Ethanol|Pressure_hPa| PM1.0| PM2_5|  NC0.5|  NC1.0|NC2.5| CNT|Fire_Alarm|          Timestamp|Year|Month|\n",
      "+----------+--------------+-----------+--------+---------+------+-----------+------------+------+------+-------+-------+-----+----+----------+-------------------+----+-----+\n",
      "|1654717046|         43.81|       32.2|   60000|     1354| 12321|      18192|     936.858|  83.3| 86.54|  573.3| 89.399|2.019|4859|         0|2022-06-08 19:37:26|2022|    6|\n",
      "|1654717055|          43.8|      32.29|   60000|     1480| 12256|      18096|     936.873|221.58|230.21|1525.05|237.813|5.371|4868|         0|2022-06-08 19:37:35|2022|    6|\n",
      "|1654717047|         43.78|      32.38|   60000|     1363| 12318|      18181|     936.867| 69.22| 71.91| 476.39| 74.287|1.678|4860|         0|2022-06-08 19:37:27|2022|    6|\n",
      "|1654717044|         43.88|      31.61|   60000|     1294| 12343|      18210|     936.842|  95.5| 99.22| 657.26|102.492|2.315|4857|         0|2022-06-08 19:37:24|2022|    6|\n",
      "|1654717048|         43.77|      32.56|   60000|     1418| 12281|      18151|      936.87| 45.53|  47.3| 313.36| 48.864|1.104|4861|         0|2022-06-08 19:37:28|2022|    6|\n",
      "|1654717050|         43.71|      32.54|   60000|     1586| 12207|      18042|     936.868| 30.87| 32.07| 212.48| 33.133|0.748|4863|         0|2022-06-08 19:37:30|2022|    6|\n",
      "|1654717054|         43.68|      32.34|   60000|     1546| 12218|      18048|     936.877|178.63|185.59|1229.45|191.718| 4.33|4867|         0|2022-06-08 19:37:34|2022|    6|\n",
      "|1654717051|         43.73|      32.53|   60000|     1614| 12202|      18041|      936.87| 27.45| 28.52| 188.94| 29.464|0.665|4864|         0|2022-06-08 19:37:31|2022|    6|\n",
      "|1654717045|         43.85|       32.0|   60000|     1297| 12351|      18216|     936.844| 99.95|103.84| 687.91|107.272|2.423|4858|         0|2022-06-08 19:37:25|2022|    6|\n",
      "|1654717052|         43.67|      32.52|   60000|     1593| 12207|      18039|     936.892| 34.55|  35.9| 237.79|  37.08|0.837|4865|         0|2022-06-08 19:37:32|2022|    6|\n",
      "+----------+--------------+-----------+--------+---------+------+-----------+------------+------+------+-------+-------+-----+----+----------+-------------------+----+-----+\n",
      "\n",
      "+----------+--------------+-----------+--------+---------+------+-----------+------------+-----+-----+-----+-----+-----+----+----------+-------------------+----+-----+\n",
      "|       UTC|Temperature[C]|Humidity[%]|TVOC_ppb|eCO2[ppm]|Raw_H2|Raw_Ethanol|Pressure_hPa|PM1.0|PM2_5|NC0.5|NC1.0|NC2.5| CNT|Fire_Alarm|          Timestamp|Year|Month|\n",
      "+----------+--------------+-----------+--------+---------+------+-----------+------------+-----+-----+-----+-----+-----+----+----------+-------------------+----+-----+\n",
      "|1654716977|         42.96|      18.48|       0|      400| 13658|      21410|      936.82| 0.87|  0.9| 5.96| 0.93|0.021|4790|         0|2022-06-08 19:36:17|2022|    6|\n",
      "|1654716978|         42.58|      18.49|       0|      400| 13659|      21410|      936.82| 0.85| 0.89| 5.88|0.916|0.021|4791|         0|2022-06-08 19:36:18|2022|    6|\n",
      "|1655129098|         5.512|      18.48|       0|      400| 13658|      21410|      936.82| 0.87|  0.9| 5.96| 0.93|0.021|4790|         0|2022-06-13 14:04:58|2022|    6|\n",
      "|1655129099|         5.443|      18.49|       0|      400| 13659|      21410|      936.82| 0.85| 0.89| 5.88|0.916|0.021|4791|         0|2022-06-13 14:04:59|2022|    6|\n",
      "|1654716979|         41.46|      18.77|       0|      400| 13646|      21402|     936.826| 0.85| 0.88| 5.82|0.908| 0.02|4792|         0|2022-06-08 19:36:19|2022|    6|\n",
      "|1655129100|         5.374|      18.77|       0|      400| 13646|      21402|     936.826| 0.85| 0.88| 5.82|0.908| 0.02|4792|         0|2022-06-13 14:05:00|2022|    6|\n",
      "|1654716012|         27.32|      39.16|       0|      400| 13430|      21401|       937.4| 1.48| 1.54|10.18|1.587|0.036|3825|         0|2022-06-08 19:20:12|2022|    6|\n",
      "|1654716976|         42.92|      18.51|       0|      400| 13655|      21401|     936.825| 0.88| 0.91| 6.02|0.939|0.021|4789|         0|2022-06-08 19:36:16|2022|    6|\n",
      "|1655128133|        13.196|      39.16|       0|      400| 13430|      21401|       937.4| 1.48| 1.54|10.18|1.587|0.036|3825|         0|2022-06-13 13:48:53|2022|    6|\n",
      "|1655129097|         5.582|      18.51|       0|      400| 13655|      21401|     936.825| 0.88| 0.91| 6.02|0.939|0.021|4789|         0|2022-06-13 14:04:57|2022|    6|\n",
      "+----------+--------------+-----------+--------+---------+------+-----------+------------+-----+-----+-----+-----+-----+----+----------+-------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top 10 Days with Highest TVOC Levels\n",
    "top_10_tvoc_days = data_with_datetime.orderBy(F.desc(\"TVOC_ppb\")).limit(10)\n",
    "top_10_tvoc_days.show()\n",
    "\n",
    "# Top 10 Days with Highest Raw Ethanol Levels\n",
    "top_10_ethanol_days = data_with_datetime.orderBy(F.desc(\"Raw_Ethanol\")).limit(10)\n",
    "top_10_ethanol_days.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccffb168-58d8-4d20-b778-63ffd78426f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+\n",
      "|Year|Month|         Avg_PM2_5|\n",
      "+----+-----+------------------+\n",
      "|2022|    6|184.46777023790509|\n",
      "+----+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute Average PM2.5 per Month\n",
    "avg_pm25_per_month = data_with_datetime.groupBy(\"Year\", \"Month\") \\\n",
    "                                       .agg(F.avg(\"PM2_5\").alias(\"Avg_PM2_5\"))\n",
    "avg_pm25_per_month.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e748cb24-6ba4-4bee-8859-544caa619de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------------+\n",
      "|Year|Month|Total_Fire_Alarms|\n",
      "+----+-----+-----------------+\n",
      "|2022|    6|            44757|\n",
      "+----+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute Total Fire Alarms per Month\n",
    "fire_alarm_count = data_with_datetime.groupBy(\"Year\", \"Month\") \\\n",
    "                                     .agg(F.sum(\"Fire_Alarm\").alias(\"Total_Fire_Alarms\"))\n",
    "fire_alarm_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167f0f85-5e1a-4ea2-b5c2-2588e01d009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----------+--------+---------+------+-----------+------------+--------+--------+--------+---------+---------+---+----------+-------------------+----+-----+\n",
      "|       UTC|Temperature[C]|Humidity[%]|TVOC_ppb|eCO2[ppm]|Raw_H2|Raw_Ethanol|Pressure_hPa|   PM1.0|   PM2_5|   NC0.5|    NC1.0|    NC2.5|CNT|Fire_Alarm|          Timestamp|Year|Month|\n",
      "+----------+--------------+-----------+--------+---------+------+-----------+------------+--------+--------+--------+---------+---------+---+----------+-------------------+----+-----+\n",
      "|1654903053|         22.11|      47.94|       0|     1405| 12961|      20049|     931.186| 7914.14| 9019.41| 52467.6| 9447.012|  965.387| 48|         1|2022-06-10 23:17:33|2022|    6|\n",
      "|1654903054|         21.94|      50.24|       0|     1402| 12962|      20043|     931.195| 9608.86| 12702.7|59301.19| 13565.18| 2872.672| 49|         1|2022-06-10 23:17:34|2022|    6|\n",
      "|1654903055|         21.81|      52.44|       0|     1448| 12942|      20036|     931.187|10356.99|15075.03|60442.71|16275.758| 4439.094| 50|         1|2022-06-10 23:17:35|2022|    6|\n",
      "|1654903056|         21.73|      53.86|       0|     1550| 12884|      20004|     931.192|11433.76|19884.37|58580.91|21845.273| 8047.641| 51|         1|2022-06-10 23:17:36|2022|    6|\n",
      "|1654903057|         21.69|      55.34|       0|     1517| 12908|      20007|     931.196|11722.13|21849.34| 56381.3|24146.516| 9671.195| 52|         1|2022-06-10 23:17:37|2022|    6|\n",
      "|1654903058|         21.66|      56.72|       0|     1498| 12909|      19994|     931.208|12107.31|24590.06|53151.68|27359.121|11952.469| 53|         1|2022-06-10 23:17:38|2022|    6|\n",
      "|1654903059|          21.6|      58.16|       0|     1539| 12889|      19974|     931.203|12158.49|25434.94|51514.74|28360.902|12722.195| 54|         1|2022-06-10 23:17:39|2022|    6|\n",
      "|1654903060|         21.56|      59.54|       0|     1516| 12899|      19965|     931.208|12266.83|27147.14|48241.31|30390.297|14277.578| 55|         1|2022-06-10 23:17:40|2022|    6|\n",
      "|1654903061|         21.56|       60.5|       0|     1539| 12896|      19945|     931.219|12251.45|27710.73|46679.25|31066.941|14839.797| 56|         1|2022-06-10 23:17:41|2022|    6|\n",
      "|1654903062|         21.52|      61.62|       0|     1534| 12894|      19928|     931.219|12705.84|30719.31|43433.61|34588.191|17312.953| 57|         1|2022-06-10 23:17:42|2022|    6|\n",
      "|1654903063|         21.49|      63.47|       0|     1476| 12923|      19940|     931.219|12456.58|30870.15|40688.44|34810.785|17704.711| 58|         1|2022-06-10 23:17:43|2022|    6|\n",
      "|1654903064|         21.52|      64.03|       5|     1487| 12917|      19917|     931.233|12874.66| 32943.8|39447.12| 37220.02|19306.086| 59|         1|2022-06-10 23:17:44|2022|    6|\n",
      "|1654903065|         21.52|       64.6|      33|     1479| 12931|      19920|     931.237|13228.08|35020.92|37583.35|39644.367|20974.461| 60|         1|2022-06-10 23:17:45|2022|    6|\n",
      "|1654903066|         21.47|      65.18|      41|     1445| 12937|      19908|     931.253|13252.56| 36124.9|35041.93|40960.555|22021.992| 61|         1|2022-06-10 23:17:46|2022|    6|\n",
      "|1654903067|         21.49|       65.8|      25|     1400| 12960|      19909|     931.256|13315.76|36893.58|33710.61|41869.164|22705.938| 62|         1|2022-06-10 23:17:47|2022|    6|\n",
      "|1654903068|         21.47|      66.37|      35|     1391| 12970|      19895|     931.262|13706.52|39270.41|31448.22|44645.625|24628.484| 63|         1|2022-06-10 23:17:48|2022|    6|\n",
      "|1654903069|          21.5|      66.84|      32|     1331| 12998|      19899|     931.264|13562.35|39427.05|29686.03|44857.371|24922.438| 64|         1|2022-06-10 23:17:49|2022|    6|\n",
      "|1654903070|         21.47|      67.39|      35|     1331| 13005|      19901|     931.258|12962.31|37786.01|28113.04|42996.336|23920.094| 65|         1|2022-06-10 23:17:50|2022|    6|\n",
      "|1654903071|          21.5|       67.8|      48|     1306| 13010|      19886|     931.258|12951.88|37239.82|29386.34|42344.867| 23400.18| 66|         1|2022-06-10 23:17:51|2022|    6|\n",
      "|1654903072|         21.52|      68.16|      51|     1277| 13030|      19886|     931.253|13495.09|39860.86|27957.59|45387.594|25409.734| 67|         1|2022-06-10 23:17:52|2022|    6|\n",
      "+----------+--------------+-----------+--------+---------+------+-----------+------------+--------+--------+--------+---------+---------+---+----------+-------------------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute Mean and Standard Deviation of PM2.5\n",
    "pm25_stats = data_with_datetime.agg(\n",
    "    F.mean(\"PM2_5\").alias(\"Mean_PM2_5\"),\n",
    "    F.stddev(\"PM2_5\").alias(\"StdDev_PM2_5\")\n",
    ").collect()\n",
    "\n",
    "mean_pm25 = pm25_stats[0][\"Mean_PM2_5\"]\n",
    "stddev_pm25 = pm25_stats[0][\"StdDev_PM2_5\"]\n",
    "\n",
    "# Filter Outliers (greater than mean + 3*stddev)\n",
    "outliers_pm25 = data_with_datetime.filter(\n",
    "    F.col(\"PM2_5\") > mean_pm25 + 3 * stddev_pm25\n",
    ")\n",
    "outliers_pm25.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7217212b-ae76-4af1-891d-8ec30abd8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80abd4ab-5b06-4ee6-bc9c-7ce2292b07a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/07 23:52:09 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "DenseMatrix([[ 1.        , -0.24398559,  0.08244183, -0.03734264],\n",
      "             [-0.24398559,  1.        , -0.4888779 ,  0.06878211],\n",
      "             [ 0.08244183, -0.4888779 ,  1.        , -0.67371463],\n",
      "             [-0.03734264,  0.06878211, -0.67371463,  1.        ]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assemble environmental variables and pollutants into a vector\n",
    "vector_col = \"features\"\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Temperature[C]\", \"Humidity[%]\", \"TVOC_ppb\", \"Raw_Ethanol\"], \n",
    "    outputCol=vector_col\n",
    ")\n",
    "\n",
    "# Transform data into vector format\n",
    "data_vector = assembler.transform(data_with_datetime)\n",
    "\n",
    "# Compute the correlation matrix for these features\n",
    "correlation_matrix = Correlation.corr(data_vector, vector_col).head()[0]\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(f\"Correlation Matrix:\\n{correlation_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be235378-baf7-40d6-910d-f682fb56c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the correlation matrix into a pandas DataFrame for easier manipulation\n",
    "correlation_matrix_df = pd.DataFrame(correlation_matrix.toArray(), columns=[\"Temperature[C]\", \"Humidity[%]\", \"TVOC_ppb\", \"Raw_Ethanol\"],\n",
    "                                      index=[\"Temperature[C]\", \"Humidity[%]\", \"TVOC_ppb\", \"Raw_Ethanol\"])\n",
    "\n",
    "# Prepare the reshaped DataFrame with Feature 1, Feature 2, and Correlation Value\n",
    "reshaped_data = []\n",
    "\n",
    "# Loop through the DataFrame to extract the correlations between pairs of features\n",
    "for feature1 in correlation_matrix_df.columns:\n",
    "    for feature2 in correlation_matrix_df.index:\n",
    "        reshaped_data.append({\n",
    "            \"Feature 1\": feature1,\n",
    "            \"Feature 2\": feature2,\n",
    "            \"Correlation Value\": correlation_matrix_df.loc[feature2, feature1]\n",
    "        })\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "correlation_matrix_reshaped_df = pd.DataFrame(reshaped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6191869-4f8d-4b7f-aeca-fc0079395449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix with Fire Alarms:\n",
      "DenseMatrix([[ 1.        , -0.24398559,  0.08244183, -0.03734264,  0.03208418],\n",
      "             [-0.24398559,  1.        , -0.4888779 ,  0.06878211, -0.17888169],\n",
      "             [ 0.08244183, -0.4888779 ,  1.        , -0.67371463,  0.47742447],\n",
      "             [-0.03734264,  0.06878211, -0.67371463,  1.        , -0.39319215],\n",
      "             [ 0.03208418, -0.17888169,  0.47742447, -0.39319215,  1.        ]])\n"
     ]
    }
   ],
   "source": [
    "# Correlate Fire Alarms with environmental conditions and chemical emissions\n",
    "assembler_fire_alarm = VectorAssembler(\n",
    "    inputCols=[\"Temperature[C]\", \"Humidity[%]\", \"TVOC_ppb\", \"Raw_Ethanol\", \"PM2_5\"],\n",
    "    outputCol=\"fire_alarm_features\"\n",
    ")\n",
    "\n",
    "# Transform data\n",
    "data_with_fire_alarm_features = assembler_fire_alarm.transform(data_with_datetime)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix_fire_alarm = Correlation.corr(data_with_fire_alarm_features, \"fire_alarm_features\").head()[0]\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(f\"Correlation Matrix with Fire Alarms:\\n{correlation_matrix_fire_alarm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e6c43-1f3a-407e-9c5c-6f7019d8faf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abc24c-8714-47c8-bb26-09eb0270a7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea038ad-07dd-4537-9bb0-dbe182741dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: s3fs in ./.local/lib/python3.9/site-packages (2024.10.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in ./.local/lib/python3.9/site-packages (from s3fs) (2.15.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.local/lib/python3.9/site-packages (from s3fs) (3.11.9)\n",
      "Requirement already satisfied: fsspec==2024.10.0.* in ./.local/lib/python3.9/site-packages (from s3fs) (2024.10.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in ./.local/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in ./.local/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.35.37,>=1.35.16 in ./.local/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.35.36)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.4.4)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.2.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.18.3)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./.local/lib/python3.9/site-packages (from aioitertools<1.0.0,>=0.5.1->aiobotocore<3.0.0,>=2.5.4->s3fs) (4.12.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/lib/python3.9/site-packages (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3.9/site-packages (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.25.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./.local/lib/python3.9/site-packages (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.9.0.post0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3.9/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "679aff13-a325-41f3-9be7-9143d43795cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.9/site-packages (2024.10.0)\n",
      "Requirement already satisfied: s3fs in ./.local/lib/python3.9/site-packages (2024.10.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in ./.local/lib/python3.9/site-packages (from s3fs) (2.15.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.local/lib/python3.9/site-packages (from s3fs) (3.11.9)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in ./.local/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in ./.local/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.35.37,>=1.35.16 in ./.local/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.35.36)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (24.2.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.18.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./.local/lib/python3.9/site-packages (from aioitertools<1.0.0,>=0.5.1->aiobotocore<3.0.0,>=2.5.4->s3fs) (4.12.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/lib/python3.9/site-packages (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3.9/site-packages (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.25.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./.local/lib/python3.9/site-packages (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.9.0.post0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3.9/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fsspec s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "075ddc9a-ee88-4dd8-b0d0-c1a5599e881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:57:52 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:57:53 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:57:55 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:57:55 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:57:57 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:57:57 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:57:58 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:57:59 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:58:00 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:58:01 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:58:02 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:58:02 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:58:04 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:58:04 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:58:05 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:58:06 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "24/12/05 22:58:06 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the S3 path for processed data\n",
    "s3_bucket = \"s3a://smoke-detection-data-pipeline/task3Transformed/\"\n",
    "\n",
    "# Save Transformed Data (with Year and Month columns)\n",
    "data_with_datetime.coalesce(1).write.csv(f\"{s3_bucket}transformed_data/\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# Save Aggregated Monthly Emissions Data\n",
    "monthly_emissions.write.csv(f\"{s3_bucket}monthly_emissions/\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# Save Monthly Environmental Trends\n",
    "monthly_environmental_trends.write.csv(f\"{s3_bucket}monthly_environmental_trends/\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# Save Top 10 Days with Highest TVOC Levels\n",
    "top_10_tvoc_days.write.csv(f\"{s3_bucket}top_10_tvoc_days/\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# Save Top 10 Days with Highest Raw Ethanol Levels\n",
    "top_10_ethanol_days.write.csv(f\"{s3_bucket}top_10_ethanol_days/\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# Save Average PM2.5 Levels Per Month\n",
    "avg_pm25_per_month.write.csv(f\"{s3_bucket}avg_pm25_per_month/\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# Save Total Fire Alarms Per Month\n",
    "fire_alarm_count.write.csv(f\"{s3_bucket}fire_alarm_count/\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# Save PM2.5 Outliers Data\n",
    "outliers_pm25.write.csv(f\"{s3_bucket}pm25_outliers/\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# Convert Correlation Matrices to Pandas DataFrame\n",
    "correlation_matrix_pd = pd.DataFrame(correlation_matrix.toArray())\n",
    "correlation_matrix_fire_alarm_pd = pd.DataFrame(correlation_matrix_fire_alarm.toArray())\n",
    "\n",
    "# Save Correlation Matrices as CSV Files in S3\n",
    "correlation_matrix_pd.to_csv(f\"{s3_bucket}corrMatrixEnvVar.csv\", index=False, header=True, storage_options={\"anon\": False})\n",
    "correlation_matrix_fire_alarm_pd.to_csv(f\"{s3_bucket}corrMatrixFireAlarm.csv\", index=False, header=True, storage_options={\"anon\": False})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22773ab2-0a43-4bdf-997a-dd5870414de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"s3a://smoke-detection-data-pipeline/task3Transformed/\"\n",
    "correlation_matrix_reshaped_df.to_csv(f\"{s3_bucket}correlation.csv\", index=False, header=True, storage_options={\"anon\": False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d90297f6-39f5-46db-ae2e-a2d874d228b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrames as SQL views\n",
    "data_with_datetime.createOrReplaceTempView(\"transformed_data\")\n",
    "monthly_emissions.createOrReplaceTempView(\"monthly_emissions\")\n",
    "monthly_environmental_trends.createOrReplaceTempView(\"monthly_environmental_trends\")\n",
    "top_10_tvoc_days.createOrReplaceTempView(\"top_10_tvoc_days\")\n",
    "top_10_ethanol_days.createOrReplaceTempView(\"top_10_ethanol_days\")\n",
    "fire_alarm_count.createOrReplaceTempView(\"fire_alarm_count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f04e103-f106-411a-961f-fbc232930c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------------+\n",
      "|Day|Total_TVOC|Total_Raw_Ethanol|\n",
      "+---+----------+-----------------+\n",
      "|  8|  40947898|        115780034|\n",
      "| 13|  40947898|        115780034|\n",
      "|  9|  39054608|        982481786|\n",
      "| 10|    680659|         23167319|\n",
      "+---+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = \"\"\"\n",
    "SELECT DAY(FROM_UNIXTIME(UTC)) AS Day,\n",
    "       SUM(TVOC_ppb) AS Total_TVOC,\n",
    "       SUM(Raw_Ethanol) AS Total_Raw_Ethanol\n",
    "FROM transformed_data\n",
    "GROUP BY Day\n",
    "ORDER BY Total_TVOC DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "highest_emissions_days = spark.sql(query1)\n",
    "highest_emissions_days.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d72e5de6-6bc4-42a1-87b9-4c52d889e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------------------+\n",
      "|Day|   Avg_Temperature|      Avg_Humidity|\n",
      "+---+------------------+------------------+\n",
      "| 10|  34.2332235701906|23.258587521663777|\n",
      "|  8|  33.7831023676881| 38.12003830083569|\n",
      "|  9|14.629292450187956| 51.51767304153025|\n",
      "| 13| 6.160041434540405| 38.12003830083566|\n",
      "+---+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT DAY(FROM_UNIXTIME(UTC)) AS Day,\n",
    "       AVG(`Temperature[C]`) AS Avg_Temperature,\n",
    "       AVG(`Humidity[%]`) AS Avg_Humidity\n",
    "FROM transformed_data\n",
    "GROUP BY Day\n",
    "ORDER BY Avg_Temperature DESC\n",
    "\"\"\"\n",
    "daily_temp_humidity = spark.sql(query2)\n",
    "daily_temp_humidity.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f7db66-0439-4c32-b0ca-e514e341589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+\n",
      "|Day|Total_Fire_Alarms|\n",
      "+---+-----------------+\n",
      "|  9|            43632|\n",
      "| 10|             1121|\n",
      "|  8|                2|\n",
      "| 13|                2|\n",
      "+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"\"\"\n",
    "SELECT DAY(FROM_UNIXTIME(UTC)) AS Day,\n",
    "       COUNT(Fire_Alarm) AS Total_Fire_Alarms\n",
    "FROM transformed_data\n",
    "WHERE Fire_Alarm = 1\n",
    "GROUP BY Day\n",
    "ORDER BY Total_Fire_Alarms DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "most_fire_alarms_days = spark.sql(query3)\n",
    "most_fire_alarms_days.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed8bb856-69bb-4f12-9f3f-480d5f2b0614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|Day|         Avg_PM2_5|\n",
      "+---+------------------+\n",
      "| 10|2973.7339428076302|\n",
      "|  8| 699.6721552924782|\n",
      "| 13| 699.6721552924782|\n",
      "|  9|1.6742770264863744|\n",
      "+---+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query4 = \"\"\"\n",
    "SELECT DAY(FROM_UNIXTIME(UTC)) AS Day,\n",
    "       AVG(PM2_5) AS Avg_PM2_5\n",
    "FROM transformed_data\n",
    "GROUP BY Day\n",
    "ORDER BY Avg_PM2_5 DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "highest_pm25_days = spark.sql(query4)\n",
    "highest_pm25_days.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b87ec12d-efe5-4bb0-98dd-5656d1016260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+------------------+----------------+\n",
      "|Day|   Avg_Temperature|     Avg_Humidity|         Avg_PM2_5|Fire_Alarm_Count|\n",
      "+---+------------------+-----------------+------------------+----------------+\n",
      "|  9|13.965375618811771| 51.5017766776682|1.8266909607627617|           43632|\n",
      "| 10| 34.60313113291699|22.69262265834077|3059.8000267618245|            1121|\n",
      "|  8|            27.295|            43.91|             2.335|               2|\n",
      "| 13|           20.2225|            43.91|             2.335|               2|\n",
      "+---+------------------+-----------------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query5 = \"\"\"\n",
    "SELECT DAY(FROM_UNIXTIME(UTC)) AS Day,\n",
    "       AVG(`Temperature[C]`) AS Avg_Temperature,\n",
    "       AVG(`Humidity[%]`) AS Avg_Humidity,\n",
    "       AVG(PM2_5) AS Avg_PM2_5,\n",
    "       COUNT(Fire_Alarm) AS Fire_Alarm_Count\n",
    "FROM transformed_data\n",
    "WHERE Fire_Alarm = 1\n",
    "GROUP BY Day\n",
    "ORDER BY Fire_Alarm_Count DESC\n",
    "\"\"\"\n",
    "fire_alarm_conditions = spark.sql(query5)\n",
    "fire_alarm_conditions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd10ae-6bd8-4849-a4b1-b540199d3461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
